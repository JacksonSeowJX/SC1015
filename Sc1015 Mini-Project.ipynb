{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1169069c",
   "metadata": {},
   "source": [
    "# SC1015 Project - Premier League Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bce862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt # we only need pyplot\n",
    "sb.set() # set the default Seaborn style for graphics\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a88337d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resultsData = pd.read_csv('results.csv')\n",
    "statsData = pd.read_csv('stats.csv')\n",
    "statsData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d478e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe694387",
   "metadata": {},
   "source": [
    "## Total of 240 Rows and 42 Columns in stats.CSV file\n",
    "\n",
    "### 2 Categorical Variables, 40 Numeric Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc90b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "statsData.info()\n",
    "statsData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4dcd99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ca1f0055",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e260e6",
   "metadata": {},
   "source": [
    "## Check for any missing values in the stats Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea990eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "statsDataFrame = pd.DataFrame(statsData)\n",
    "\n",
    "# Check for missing values in each column\n",
    "missing_values = statsDataFrame.isnull().sum()\n",
    "\n",
    "# Print the number of missing values for each column\n",
    "print(missing_values)\n",
    "print()\n",
    "\n",
    "# Filter out columns that have missing values and print them\n",
    "missing_values_filtered = missing_values[missing_values > 0]\n",
    "if len(missing_values_filtered) > 0:\n",
    "    print(\"Columns with missing values and their count:\")\n",
    "    print(missing_values_filtered)\n",
    "else:\n",
    "    print(\"There are no missing values in any column.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3e0ddf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05febe2b",
   "metadata": {},
   "source": [
    "## Check the skewness for each of the columns with missing values\n",
    "\n",
    "### Total of 6 columns with missing values will be placed in a pd DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c121500",
   "metadata": {},
   "outputs": [],
   "source": [
    "missingValueColumns = pd.DataFrame(statsDataFrame[['saves', 'head_clearance', 'total_through_ball', 'backward_pass', 'big_chance_missed', 'dispossessed']])\n",
    "missingValueColumns.skew()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680d892b",
   "metadata": {},
   "source": [
    "### Analysis:\n",
    "\n",
    "saves (0.392526): This shows a moderate positive skew, suggesting that most of the data are concentrated on the lower end, with fewer high values extending the tail to the right.\n",
    "\n",
    "head_clearance (0.519139): Also indicates a moderate positive skew. Similar to \"saves\", most data points are lower, with some high values stretching the distribution to the right.\n",
    "\n",
    "total_through_ball (1.725295): This has a high positive skewness, indicating a significant number of lower values and a long tail towards the higher values. This suggests that very high values are relatively rare but significantly impact the distribution's shape.\n",
    "\n",
    "backward_pass (0.713525): Shows a positive skew but less extreme than total_through_ball. It indicates a concentration of data towards lower values with a tail of higher values.\n",
    "\n",
    "big_chance_missed (1.065818): With a positive skewness greater than 1, this distribution has a long right tail. There are significantly more lower values, with the higher values stretching the distribution.\n",
    "\n",
    "dispossessed (0.639976): Exhibits a moderate positive skew, indicating a concentration of lower values with a tail of higher values, but not as pronounced as total_through_ball or big_chance_missed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c731e14",
   "metadata": {},
   "source": [
    "Due to the existence of missing values, we decided to exclude the columns for head_clearance, total_through_ball, backward_pass, dispossessed, and saves. These columns pertain to actions such as clearing the ball using the head, executing passes in dynamic situations, making passes back towards one's own side, losing possession to an opponent, and preventing shots from scoring.\n",
    "\n",
    "As a result, we are now concentrating on the 'big_chance_missed' columns, which we consider to be a strong predictor of a team's goals scored and its standing. The 'big_chance_missed' metric records significant scoring opportunities that were not capitalized on, potentially altering the outcome of a game.\n",
    "\n",
    "Based on the positive skewness of the data, median imputation is generally more robust than mean imputation. The median is less affected by outliers and skewed data, making it a more representative measure of central tendency for skewed distributions. Therefore based on this, we decided to fill in the missing values for the saves and big_chance_missed, based on the median value for each club (20 Clubs total)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6ce05b",
   "metadata": {},
   "source": [
    "## Dropping of columns: head_clearance, total_through_ball, backward_pass, dispossessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f4ef6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "statsDataFrame.drop(columns=['head_clearance', 'total_through_ball', 'backward_pass', 'dispossessed', 'saves'], inplace=True)\n",
    "statsDataFrame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd2c034",
   "metadata": {},
   "source": [
    "### statsDataFrame now has 37 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fa53e5",
   "metadata": {},
   "source": [
    "## Fill in missing values for big_chance_missed using Median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55909b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derby County/Charlton Athletic/Sheffield United/Portsmouth\n",
    "filtered_indices = statsDataFrame['team'] == 'Arsenal'\n",
    "median = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].median()\n",
    "print(\"Median of filtered column:\", median)\n",
    "statsDataFrame.loc[filtered_indices, 'big_chance_missed'] = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].fillna(median)\n",
    "\n",
    "filtered_indices = statsDataFrame['team'] == 'Aston Villa'\n",
    "median = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].median()\n",
    "print(\"Median of filtered column:\", median)\n",
    "statsDataFrame.loc[filtered_indices, 'big_chance_missed'] = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].fillna(median)\n",
    "\n",
    "filtered_indices = statsDataFrame['team'] == 'Birmingham City'\n",
    "median = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].median()\n",
    "print(\"Median of filtered column:\", median)\n",
    "statsDataFrame.loc[filtered_indices, 'big_chance_missed'] = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].fillna(median)\n",
    "\n",
    "filtered_indices = statsDataFrame['team'] == 'Blackburn Rovers'\n",
    "median = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].median()\n",
    "print(\"Median of filtered column:\", median)\n",
    "statsDataFrame.loc[filtered_indices, 'big_chance_missed'] = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].fillna(median)\n",
    "\n",
    "filtered_indices = statsDataFrame['team'] == 'Bolton Wanderers'\n",
    "median = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].median()\n",
    "print(\"Median of filtered column:\", median)\n",
    "statsDataFrame.loc[filtered_indices, 'big_chance_missed'] = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].fillna(median)\n",
    "\n",
    "filtered_indices = statsDataFrame['team'] == 'Burnley'\n",
    "median = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].median()\n",
    "print(\"Median of filtered column:\", median)\n",
    "statsDataFrame.loc[filtered_indices, 'big_chance_missed'] = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].fillna(median)\n",
    "\n",
    "filtered_indices = statsDataFrame['team'] == 'Charlton Athletic'\n",
    "median = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].median()\n",
    "print(\"Median of filtered column:\", median)\n",
    "statsDataFrame.loc[filtered_indices, 'big_chance_missed'] = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].fillna(median)\n",
    "\n",
    "filtered_indices = statsDataFrame['team'] == 'Chelsea'\n",
    "median = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].median()\n",
    "print(\"Median of filtered column:\", median)\n",
    "statsDataFrame.loc[filtered_indices, 'big_chance_missed'] = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].fillna(median)\n",
    "\n",
    "filtered_indices = statsDataFrame['team'] == 'Derby County'\n",
    "median = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].median()\n",
    "print(\"Median of filtered column:\", median)\n",
    "statsDataFrame.loc[filtered_indices, 'big_chance_missed'] = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].fillna(median)\n",
    "\n",
    "filtered_indices = statsDataFrame['team'] == 'Everton'\n",
    "median = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].median()\n",
    "print(\"Median of filtered column:\", median)\n",
    "statsDataFrame.loc[filtered_indices, 'big_chance_missed'] = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].fillna(median)\n",
    "\n",
    "filtered_indices = statsDataFrame['team'] == 'Fulham'\n",
    "median = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].median()\n",
    "print(\"Median of filtered column:\", median)\n",
    "statsDataFrame.loc[filtered_indices, 'big_chance_missed'] = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].fillna(median)\n",
    "\n",
    "filtered_indices = statsDataFrame['team'] == 'Hull City'\n",
    "median = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].median()\n",
    "print(\"Median of filtered column:\", median)\n",
    "statsDataFrame.loc[filtered_indices, 'big_chance_missed'] = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].fillna(median)\n",
    "\n",
    "filtered_indices = statsDataFrame['team'] == 'Liverpool'\n",
    "median = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].median()\n",
    "print(\"Median of filtered column:\", median)\n",
    "statsDataFrame.loc[filtered_indices, 'big_chance_missed'] = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].fillna(median)\n",
    "\n",
    "filtered_indices = statsDataFrame['team'] == 'Manchester City'\n",
    "median = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].median()\n",
    "print(\"Median of filtered column:\", median)\n",
    "statsDataFrame.loc[filtered_indices, 'big_chance_missed'] = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].fillna(median)\n",
    "\n",
    "filtered_indices = statsDataFrame['team'] == 'Manchester United'\n",
    "median = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].median()\n",
    "print(\"Median of filtered column:\", median)\n",
    "statsDataFrame.loc[filtered_indices, 'big_chance_missed'] = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].fillna(median)\n",
    "\n",
    "filtered_indices = statsDataFrame['team'] == 'Middlesbrough'\n",
    "median = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].median()\n",
    "print(\"Median of filtered column:\", median)\n",
    "statsDataFrame.loc[filtered_indices, 'big_chance_missed'] = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].fillna(median)\n",
    "\n",
    "filtered_indices = statsDataFrame['team'] == 'Newcastle United'\n",
    "median = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].median()\n",
    "print(\"Median of filtered column:\", median)\n",
    "statsDataFrame.loc[filtered_indices, 'big_chance_missed'] = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].fillna(median)\n",
    "\n",
    "filtered_indices = statsDataFrame['team'] == 'Reading'\n",
    "median = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].median()\n",
    "print(\"Median of filtered column:\", median)\n",
    "statsDataFrame.loc[filtered_indices, 'big_chance_missed'] = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].fillna(median)\n",
    "\n",
    "filtered_indices = statsDataFrame['team'] == 'Portsmouth'\n",
    "median = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].median()\n",
    "print(\"Median of filtered column:\", median)\n",
    "statsDataFrame.loc[filtered_indices, 'big_chance_missed'] = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].fillna(median)\n",
    "\n",
    "filtered_indices = statsDataFrame['team'] == 'Sheffield United'\n",
    "median = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].median()\n",
    "print(\"Median of filtered column:\", median)\n",
    "statsDataFrame.loc[filtered_indices, 'big_chance_missed'] = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].fillna(median)\n",
    "\n",
    "filtered_indices = statsDataFrame['team'] == 'Sunderland'\n",
    "median = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].median()\n",
    "print(\"Median of filtered column:\", median)\n",
    "statsDataFrame.loc[filtered_indices, 'big_chance_missed'] = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].fillna(median)\n",
    "\n",
    "filtered_indices = statsDataFrame['team'] == 'Stoke City'\n",
    "median = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].median()\n",
    "print(\"Median of filtered column:\", median)\n",
    "statsDataFrame.loc[filtered_indices, 'big_chance_missed'] = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].fillna(median)\n",
    "\n",
    "filtered_indices = statsDataFrame['team'] == 'Tottenham Hotspur'\n",
    "median = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].median()\n",
    "print(\"Median of filtered column:\", median)\n",
    "statsDataFrame.loc[filtered_indices, 'big_chance_missed'] = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].fillna(median)\n",
    "\n",
    "filtered_indices = statsDataFrame['team'] == 'Watford'\n",
    "median = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].median()\n",
    "print(\"Median of filtered column:\", median)\n",
    "statsDataFrame.loc[filtered_indices, 'big_chance_missed'] = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].fillna(median)\n",
    "\n",
    "filtered_indices = statsDataFrame['team'] == 'West Ham United'\n",
    "median = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].median()\n",
    "print(\"Median of filtered column:\", median)\n",
    "statsDataFrame.loc[filtered_indices, 'big_chance_missed'] = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].fillna(median)\n",
    "\n",
    "filtered_indices = statsDataFrame['team'] == 'West Bromwich Albion'\n",
    "median = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].median()\n",
    "print(\"Median of filtered column:\", median)\n",
    "statsDataFrame.loc[filtered_indices, 'big_chance_missed'] = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].fillna(median)\n",
    "\n",
    "filtered_indices = statsDataFrame['team'] == 'Wigan Athletic'\n",
    "median = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].median()\n",
    "print(\"Median of filtered column:\", median)\n",
    "statsDataFrame.loc[filtered_indices, 'big_chance_missed'] = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].fillna(median)\n",
    "\n",
    "\n",
    "filtered_indices = statsDataFrame['team'] == 'Wolverhampton Wanderers'\n",
    "median = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].median()\n",
    "print(\"Median of filtered column:\", median)\n",
    "statsDataFrame.loc[filtered_indices, 'big_chance_missed'] = statsDataFrame.loc[filtered_indices, 'big_chance_missed'].fillna(median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac84be2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f9d9fa7",
   "metadata": {},
   "source": [
    "## Adding of new column \"Draw\" to the statsDataFrame\n",
    "\n",
    "Upon reviewing the statsDataFrame, we noticed the absence of a \"draw\" column that would reflect the number of draws a football team had during the season. Considering each team plays 38 matches annually, we computed the \"draw\" figures by deducting the sum of wins and losses from 38. After calculating this data, we would integrate this new \"draw\" column into the existing dataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5385698e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the \"draw\" column first\n",
    "statsDataFrame['draw'] = 38 - statsDataFrame['wins'] - statsDataFrame['losses']\n",
    "\n",
    "# Get the position of the 'losses' column\n",
    "# The new column will be inserted at position + 1\n",
    "position = statsDataFrame.columns.get_loc('losses') + 1\n",
    "\n",
    "# Insert the 'draw' column next to 'losses'\n",
    "statsDataFrame.insert(position, 'draw_temp', statsDataFrame['draw'])\n",
    "\n",
    "# Drop the original 'draw' column and rename 'draw_temp' to 'draw'\n",
    "statsDataFrame.drop('draw', axis=1, inplace=True)\n",
    "statsDataFrame.rename(columns={'draw_temp': 'draw'}, inplace=True)\n",
    "\n",
    "statsDataFrame.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61131d9",
   "metadata": {},
   "source": [
    "## Adding of new column \"total_points\" to the statsDataFrame\n",
    "\n",
    "Using wins and draw to tally the total points; 1 win = 3 points, 1 draw = 1 point. \n",
    "At the end of each season, team with most points would win."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86e09e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the \"total_points\" column first\n",
    "statsDataFrame['total_points'] = statsDataFrame['wins'] * 3 + statsDataFrame['draw'] \n",
    "\n",
    "# Get the position of the 'draw' column\n",
    "# The new column will be inserted at position + 1\n",
    "position = statsDataFrame.columns.get_loc('draw') + 1\n",
    "\n",
    "# Insert the 'total_points' column next to 'draw'\n",
    "statsDataFrame.insert(position, 'total_points_temp', statsDataFrame['total_points'])\n",
    "\n",
    "# Drop the original 'draw' column and rename 'draw_temp' to 'draw'\n",
    "statsDataFrame.drop('total_points', axis=1, inplace=True)\n",
    "statsDataFrame.rename(columns={'total_points_temp': 'total_points'}, inplace=True)\n",
    "\n",
    "statsDataFrame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675a9b53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d3772287",
   "metadata": {},
   "source": [
    "## Adding of new column \"goal_difference\" to the statsDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51212e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming statsDataFrame is your existing DataFrame\n",
    "\n",
    "# Calculate the goal difference for each club for each season\n",
    "statsDataFrame['goal_difference'] = statsDataFrame['goals'] - statsDataFrame['goals_conceded']\n",
    "\n",
    "total_points_index = statsDataFrame.columns.get_loc('total_points') + 1\n",
    "\n",
    "# Reorder columns to place 'goal_difference' next to 'total_points'\n",
    "statsDataFrame = statsDataFrame.reindex(columns= [*statsDataFrame.columns[:total_points_index],\n",
    "                                                  'goal_difference',\n",
    "                                                  *statsDataFrame.columns[total_points_index:-1]])\n",
    "\n",
    "statsDataFrame.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8199b9",
   "metadata": {},
   "source": [
    "## Adding of new column \"placing\" to the statsDataFrame\n",
    "\"Placing\" will mean the position the team finished in for the season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e524b546",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define the column variable to sort by\n",
    "column_to_sort = 'total_points'\n",
    "secondary_sort_column = 'goal_difference'\n",
    "# Function to sort every 20 rows based on a column and modify the main DataFrame\n",
    "def sort_every_20(df, column, secondary_column):\n",
    "    for i in range(0, len(df), 20):\n",
    "        subset = df.iloc[i:i+20]\n",
    "        sorted_subset = subset.sort_values(by=[column, secondary_column], ascending=[False, False])\n",
    "        df.iloc[i:i+20] = sorted_subset.values\n",
    "    return df\n",
    "\n",
    "# Call the function with your DataFrame\n",
    "sorted_statsDataFrame = sort_every_20(statsDataFrame, column_to_sort,secondary_sort_column)\n",
    "\n",
    "print(sorted_statsDataFrame)\n",
    "statsDataFrame['placing'] = np.tile(range(1, 21), 12)[:len(statsDataFrame)]\n",
    "\n",
    "\n",
    "# Get the position of the 'total_points' column\n",
    "# The new column will be inserted at position + 1\n",
    "position = statsDataFrame.columns.get_loc('total_points') + 1\n",
    "\n",
    "# Insert the 'placing' column next to 'draw'\n",
    "statsDataFrame.insert(position, 'placing_temp', statsDataFrame['placing'])\n",
    "\n",
    "# Drop the original 'draw' column and rename 'draw_temp' to 'draw'\n",
    "statsDataFrame.drop('placing', axis=1, inplace=True)\n",
    "statsDataFrame.rename(columns={'placing_temp': 'placing'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b19bb2",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a4551a",
   "metadata": {},
   "outputs": [],
   "source": [
    "points = pd.DataFrame(statsDataFrame['total_points']) # Response\n",
    "goals = pd.DataFrame(statsDataFrame['goals'])\n",
    "goals_conceded = pd.DataFrame(statsDataFrame['goals_conceded'])\n",
    "touches = pd.DataFrame(statsDataFrame['touches'])\n",
    "clean_sheet = pd.DataFrame(statsDataFrame['clean_sheet'])\n",
    "total_scoring_att = pd.DataFrame(statsDataFrame['total_scoring_att'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdd2179",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Set up matplotlib figure with three subplots\n",
    "f, axes = plt.subplots(6, 3, figsize=(28, 28))\n",
    "\n",
    "# Plot the basic uni-variate figures for total points\n",
    "sb.boxplot(data = points, orient = \"h\", ax = axes[0,0])\n",
    "sb.histplot(data = points, ax = axes[0,1])\n",
    "sb.violinplot(data = points, orient = \"h\", ax = axes[0,2])\n",
    "\n",
    "# Plot the basic uni-variate figures for goals\n",
    "sb.boxplot(data = goals, orient = \"h\", ax = axes[1,0])\n",
    "sb.histplot(data = goals, ax = axes[1,1])\n",
    "sb.violinplot(data = goals, orient = \"h\", ax = axes[1,2])\n",
    "\n",
    "# Plot the basic uni-variate figures for goal_conceded\n",
    "sb.boxplot(data = goals_conceded, orient = \"h\", ax = axes[2,0])\n",
    "sb.histplot(data = goals_conceded, ax = axes[2,1])\n",
    "sb.violinplot(data = goals_conceded, orient = \"h\", ax = axes[2,2])\n",
    "\n",
    "# Plot the basic uni-variate figures for touches\n",
    "sb.boxplot(data = touches, orient = \"h\", ax = axes[3,0])\n",
    "sb.histplot(data = touches, ax = axes[3,1])\n",
    "sb.violinplot(data = touches, orient = \"h\", ax = axes[3,2])\n",
    "\n",
    "# Plot the basic uni-variate figures for clean_sheet\n",
    "sb.boxplot(data = clean_sheet, orient = \"h\", ax = axes[4,0])\n",
    "sb.histplot(data = clean_sheet, ax = axes[4,1])\n",
    "sb.violinplot(data = clean_sheet, orient = \"h\", ax = axes[4,2])\n",
    "\n",
    "# Plot the basic uni-variate figures for total_scoring_att\n",
    "sb.boxplot(data = total_scoring_att, orient = \"h\", ax = axes[5,0])\n",
    "sb.histplot(data = total_scoring_att, ax = axes[5,1])\n",
    "sb.violinplot(data = total_scoring_att, orient = \"h\", ax = axes[5,2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b3d2534",
   "metadata": {},
   "source": [
    "## Correlation Matrix between variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c863079",
   "metadata": {},
   "outputs": [],
   "source": [
    "jointDF = pd.concat([points, goals, goals_conceded, touches, clean_sheet, total_scoring_att], axis = 1).reindex(points.index)\n",
    "f = plt.figure(figsize = (10,8))\n",
    "sb.heatmap(jointDF.corr(), vmin = -1, vmax = 1, linewidths = 1, annot = True, fmt = \".2f\", annot_kws = {\"size\" : 18})\n",
    "jointDF.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7951656e",
   "metadata": {},
   "source": [
    "### Analysis:\n",
    "\n",
    "Goals: Highly positively correlated with total points (0.90), it gets in line for considering to be added to the model.\n",
    "\n",
    "Goals Conceded: The defender of a team is another prospect with a strong negative correlation with total points (-0.84) and hence might be included in the list as indicator of the defensive strength.\n",
    "\n",
    "Touches and Clean Sheet: Sufficiently related with total points (0.71 and 0.79 respectively), indicating they are very important and remember that this strongly correlated with each other (that is the coefficient is 0.56), suggesting multicollinearity if both are included.\n",
    "\n",
    "Total Scoring Att: In high degree positive correlation with total points (0.76) this factor shows great individual impact upon the overall team result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fae57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "statsDataFrame.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344b080c",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "As we aim to derive valuable insights that contribute to football betting, we plan to explore the relationship between total points and the variables 'goals', 'goals_conceded', 'clean_sheet', 'total_scoring_att', and 'goal_fastbreak' using multivariate linear regression. We intend to structure our data to model it as a time series. For instance, we'll use data from 2006-2015 as training data to test against the 2016 season, and data from 2006-2016 as training data to test against the 2017 season, and so on. The model will predict the total points based on the predictors mentioned above. By testing the model against the data from 2016, 2017, and 2018, we will evaluate whether the model’s prediction accuracy is sufficiently reliable to forecast subsequent season winners."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfeb9f34",
   "metadata": {},
   "source": [
    "## Bivariate Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e7a8cd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Data splits for multiple seasons\n",
    "season_splits = {\n",
    "    \"9_seasons\": (statsDataFrame.iloc[:180], statsDataFrame.iloc[181:201]),\n",
    "    \"10_seasons\": (statsDataFrame.iloc[:200], statsDataFrame.iloc[201:221]),\n",
    "    \"11_seasons\": (statsDataFrame.iloc[:220], statsDataFrame.iloc[221:241])\n",
    "}\n",
    "\n",
    "predictors = [\"goals\", \"goals_conceded\", \"clean_sheet\", \"total_scoring_att\", \"goal_fastbreak\"]\n",
    "\n",
    "# Initialize a Linear Regression model\n",
    "linreg = LinearRegression()\n",
    "\n",
    "# Setup the figure for plotting\n",
    "fig, axes = plt.subplots(nrows=len(season_splits), ncols=len(predictors), figsize=(20, 15), constrained_layout=True)\n",
    "if len(season_splits) == 1:  # Handling the case where there's only one row\n",
    "    axes = [axes]\n",
    "\n",
    "# Iterate over each season and each predictor\n",
    "for season_index, (season, (train_data, test_data)) in enumerate(season_splits.items()):\n",
    "    print(f\"Model results for training on {season} and testing on the next season:\")\n",
    "    for predictor_index, predictor in enumerate(predictors):\n",
    "        # Fit the model using training data for each predictor\n",
    "        X_train = train_data[[predictor]]\n",
    "        y_train = train_data[\"total_points\"]\n",
    "        linreg.fit(X_train, y_train)\n",
    "        \n",
    "        # Compute R² and predict on training data to compute MSE\n",
    "        train_score = linreg.score(X_train, y_train)\n",
    "        y_train_pred = linreg.predict(X_train)\n",
    "        train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "        \n",
    "        # Predict on testing data\n",
    "        X_test = test_data[[predictor]]\n",
    "        y_test = test_data[\"total_points\"]\n",
    "        test_score = linreg.score(X_test, y_test)\n",
    "        y_test_pred = linreg.predict(X_test)\n",
    "        test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "        \n",
    "        # Plotting\n",
    "        ax = axes[season_index][predictor_index]\n",
    "        ax.scatter(X_train, y_train, color=\"blue\", label=\"Training Data\")\n",
    "        ax.plot(X_train, y_train_pred, color=\"black\", label=\"Model Prediction\")\n",
    "        ax.scatter(X_test, y_test, color=\"red\", label=\"Test Data\")\n",
    "        ax.set_title(f\"{season} - {predictor}\")\n",
    "        ax.set_xlabel(predictor)\n",
    "        ax.set_ylabel(\"Total Points\")\n",
    "        ax.legend()\n",
    "\n",
    "        # Print the results including intercept and coefficients\n",
    "        print(f\"Model details for predictor: {predictor}\")\n",
    "        print(f\" Intercept of Regression: {linreg.intercept_}\")\n",
    "        print(f\" Coefficient of Regression for {predictor}: {linreg.coef_[0]}\")\n",
    "        print(f\" Goodness of Fit - Train Dataset:\")\n",
    "        print(f\"  R^2 = {train_score:.4f}\")\n",
    "        print(f\"  MSE = {train_mse:.4f}\")\n",
    "        print(f\" Goodness of Fit - Test Dataset:\")\n",
    "        print(f\"  R^2 = {test_score:.4f}\")\n",
    "        print(f\"  MSE = {test_mse:.4f}\")\n",
    "        print()\n",
    "    print(\"-----------------------------------------------------------------\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12393e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "statsDataFrame.head(181)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208bd933",
   "metadata": {},
   "source": [
    "## Multivariate Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01644c65",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "train_data_9_seasons = statsDataFrame.iloc[:180]   # First 9 seasons samples for training\n",
    "test_data_10th_season = statsDataFrame.iloc[181:201]   # Number 10th season sample for testing\n",
    "\n",
    "train_data_10_seasons = statsDataFrame.iloc[:200]   # First 10 seasons samples for training\n",
    "test_data_11th_season = statsDataFrame.iloc[201:221]   # Number 11th sample for testing\n",
    "\n",
    "train_data_11_seasons = statsDataFrame.iloc[:220]   # First 11 seasons samples for training\n",
    "test_data_12th_season = statsDataFrame.iloc[221:241]   # Number 12th sample for testing\n",
    "\n",
    "\n",
    "# Function to train the model and plot results\n",
    "def train_and_plot(X_train, y_train, X_test, y_test, title_suffix):\n",
    "    linreg = LinearRegression()\n",
    "    linreg.fit(X_train, y_train)\n",
    "\n",
    "    # Output the intercept and coefficients\n",
    "    print(f'Intercept of Regression for {title_suffix}: b = ', linreg.intercept_)\n",
    "    print(f'Coefficients of Regression for {title_suffix}:')\n",
    "    # Ensure that coefficients are formatted as a list of lists (if they are not already)\n",
    "    coef_list = linreg.coef_.tolist()[0] if len(linreg.coef_.shape) > 1 else linreg.coef_.tolist()\n",
    "    print(pd.DataFrame(list(zip(X_train.columns, coef_list)), columns=[\"Predictors\", \"Coefficients\"]))\n",
    "    print()\n",
    "\n",
    "    # Predictions\n",
    "    y_train_pred = linreg.predict(X_train)\n",
    "    y_test_pred = linreg.predict(X_test)\n",
    "\n",
    "    # Visualization\n",
    "    f, axes = plt.subplots(1, 2, figsize=(24, 12))\n",
    "    axes[0].scatter(y_train, y_train_pred, color=\"blue\")\n",
    "    axes[0].plot(y_train, y_train, 'w-', linewidth=1)\n",
    "    axes[0].set_xlabel(\"True values of the Response Variable (Train)\")\n",
    "    axes[0].set_ylabel(\"Predicted values of the Response Variable (Train)\")\n",
    "    axes[0].set_title(f\"Train Predictions for {title_suffix}\")\n",
    "\n",
    "    axes[1].scatter(y_test, y_test_pred, color=\"green\")\n",
    "    axes[1].plot(y_test, y_test, 'w-', linewidth=1)\n",
    "    axes[1].set_xlabel(\"True values of the Response Variable (Test)\")\n",
    "    axes[1].set_ylabel(\"Predicted values of the Response Variable (Test)\")\n",
    "    axes[1].set_title(f\"Test Predictions for {title_suffix}\")\n",
    "    plt.show()\n",
    "\n",
    "    # Goodness of Fit\n",
    "    print(f\"Goodness of Fit of Model \\tTrain Dataset ({title_suffix})\")\n",
    "    print(\"Explained Variance (R^2) \\t:\", linreg.score(X_train, y_train))\n",
    "    print(\"Mean Squared Error (MSE) \\t:\", mean_squared_error(y_train, y_train_pred))\n",
    "    print()\n",
    "\n",
    "    print(f\"Goodness of Fit of Model \\tTest Dataset ({title_suffix})\")\n",
    "    print(\"Explained Variance (R^2) \\t:\", linreg.score(X_test, y_test))\n",
    "    print(\"Mean Squared Error (MSE) \\t:\", mean_squared_error(y_test, y_test_pred))\n",
    "    print()\n",
    "    \n",
    "# Train and test for the 9th season\n",
    "X_train = train_data_9_seasons[[\"goals\", \"goals_conceded\", \"clean_sheet\", \"total_scoring_att\", \"goal_fastbreak\"]]\n",
    "y_train = train_data_9_seasons[\"total_points\"]\n",
    "X_test = test_data_10th_season[[\"goals\", \"goals_conceded\", \"clean_sheet\", \"total_scoring_att\", \"goal_fastbreak\"]]\n",
    "y_test = test_data_10th_season[\"total_points\"]\n",
    "\n",
    "train_and_plot(X_train, y_train, X_test, y_test, \"9 Seasons Training, Test on 10th Season\")\n",
    "\n",
    "# Train and test for the 10th season\n",
    "X_train = train_data_10_seasons[[\"goals\", \"goals_conceded\", \"clean_sheet\", \"total_scoring_att\", \"goal_fastbreak\"]]\n",
    "y_train = train_data_10_seasons[\"total_points\"]\n",
    "X_test = test_data_11th_season[[\"goals\", \"goals_conceded\", \"clean_sheet\", \"total_scoring_att\", \"goal_fastbreak\"]]\n",
    "y_test = test_data_11th_season[\"total_points\"]\n",
    "\n",
    "train_and_plot(X_train, y_train, X_test, y_test, \"10 Seasons Training, Test on 11th Season\")\n",
    "\n",
    "# Train and test for the 11th season\n",
    "X_train = train_data_11_seasons[[\"goals\", \"goals_conceded\", \"clean_sheet\", \"total_scoring_att\", \"goal_fastbreak\"]]\n",
    "y_train = train_data_11_seasons[\"total_points\"]\n",
    "X_test = test_data_12th_season[[\"goals\", \"goals_conceded\", \"clean_sheet\", \"total_scoring_att\", \"goal_fastbreak\"]]\n",
    "y_test = test_data_12th_season[\"total_points\"]\n",
    "\n",
    "train_and_plot(X_train, y_train, X_test, y_test, \"11 Seasons Training, Test on 12th Season\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0c3c0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4bdd359b",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f4657c",
   "metadata": {},
   "source": [
    "# Extra code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc2c855",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_seasons = set(statsDataFrame['season'].unique())\n",
    "\n",
    "# Group by 'team' and aggregate seasons into a set for each team\n",
    "teams_seasons = statsDataFrame.groupby('team')['season'].agg(set)\n",
    "\n",
    "# Filter teams that have data for all seasons\n",
    "consistent_teams = teams_seasons[teams_seasons.apply(lambda x: x == all_seasons)]\n",
    "\n",
    "# Extract the list of consistent teams\n",
    "consistent_team_list = consistent_teams.index.tolist()\n",
    "\n",
    "# Filter the original DataFrame to include only consistent teams\n",
    "filtered_df = statsDataFrame[statsDataFrame['team'].isin(consistent_team_list)]\n",
    "print(\"Teams that appeared in all seasons:\", consistent_team_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed4511c",
   "metadata": {},
   "source": [
    "## Adding of new column \"qualifications\" to the statsDataFrame\n",
    "\n",
    "Positions 1-4 qualify for champion's league | Position(s) 5 qualify for europa league | Positions 18-20 qualify for relegation | Remaining positions do not qualify for any other leagues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723b1915",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def determine_qualification(placing):\n",
    "    if 1 <= placing <= 4:\n",
    "        return 'Champions League'\n",
    "    elif placing == 5:\n",
    "        return 'Europa League'\n",
    "    elif 18 <= placing <= 20:\n",
    "        return 'Relegation'\n",
    "    else:\n",
    "        return 'No qualifications'\n",
    "\n",
    "    \n",
    "statsDataFrame['qualifications'] = statsDataFrame['placing'].apply(determine_qualification)\n",
    "# Find the index of the 'placement' column\n",
    "placement_index = statsDataFrame.columns.get_loc('placing')\n",
    "\n",
    "# Insert the 'qualifications' column right after the 'placement' column\n",
    "# We use placement_index + 1 to place it right after the 'placement' column\n",
    "statsDataFrame.insert(placement_index + 1, 'qualifications_new', statsDataFrame['qualifications'])\n",
    "\n",
    "# Now you can drop the old 'qualifications' column since it's duplicated\n",
    "statsDataFrame.drop('qualifications', axis=1, inplace=True)\n",
    "\n",
    "# Rename the new column back to 'qualifications'\n",
    "statsDataFrame.rename(columns={'qualifications_new': 'qualifications'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ae8bea",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## Adding of new column \"presence\" to the statsDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d4d30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "statsDataFrame['presence'] = 'Present'\n",
    "\n",
    "# Find the index of the 'team' column\n",
    "team_index = statsDataFrame.columns.get_loc('team')\n",
    "\n",
    "# Insert the 'presence' column right after the 'team' column\n",
    "statsDataFrame.insert(team_index + 1, 'presence_new', statsDataFrame['presence'])\n",
    "\n",
    "# Drop the old 'presence' column since it's now duplicated\n",
    "statsDataFrame.drop('presence', axis=1, inplace=True)\n",
    "\n",
    "# Optionally, rename the new column back to 'presence'\n",
    "statsDataFrame.rename(columns={'presence_new': 'presence'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdfdbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#statsDataFrame.to_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ac68c9",
   "metadata": {},
   "source": [
    "## Adding of new entries for teams that were absent throughout the 2006-2018 seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfe8c9e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Assuming statsDataFrame is already loaded\n",
    "number_of_unique_clubs = statsDataFrame['team'].nunique()\n",
    "all_clubs = set(statsDataFrame['team'].unique())  # Get a set of all unique clubs\n",
    "\n",
    "# Get all unique seasons\n",
    "unique_seasons = statsDataFrame['season'].unique()\n",
    "\n",
    "# Dictionary to hold seasons and the clubs that did not appear\n",
    "missing_clubs_by_season = {}\n",
    "\n",
    "for season in unique_seasons:\n",
    "    # Get the set of clubs that appeared in this season\n",
    "    clubs_in_season = set(statsDataFrame[statsDataFrame['season'] == season]['team'])\n",
    "    \n",
    "    # Find clubs that did not appear in this season by subtracting the sets\n",
    "    missing_clubs = all_clubs - clubs_in_season\n",
    "    \n",
    "    # Store the missing clubs in the dictionary\n",
    "    missing_clubs_by_season[season] = missing_clubs\n",
    "    \n",
    "    # Print out the missing clubs for this season\n",
    "    if missing_clubs:\n",
    "        print(f\"Missing clubs in {season}: {', '.join(missing_clubs)}\")\n",
    "    else:\n",
    "        print(f\"All clubs were present in {season}.\")\n",
    "\n",
    "        \n",
    "###########################################################################\n",
    "\n",
    "# Define the columns to be zeroed or defaulted\n",
    "stats_columns = [col for col in statsDataFrame.columns if col not in ['team', 'season', 'presence']]\n",
    "default_values = {col: 0 for col in stats_columns}  # Set default values for stats to zero\n",
    "\n",
    "# List to store new row data\n",
    "new_rows = []\n",
    "\n",
    "\n",
    "for season, clubs in missing_clubs_by_season.items():\n",
    "    for club in clubs:\n",
    "        new_row = {'team': club, 'season': season, 'presence': 'Absent'}\n",
    "        new_row.update(default_values)  # Update the row with default values for other stats\n",
    "        new_rows.append(new_row)\n",
    "        \n",
    "# Convert list of new rows to DataFrame\n",
    "new_entries_df = pd.DataFrame(new_rows)\n",
    "\n",
    "# Concatenate this new DataFrame to the existing statsDataFrame\n",
    "statsDataFrame = pd.concat([statsDataFrame, new_entries_df], ignore_index=True)\n",
    "\n",
    "###################################################################\n",
    "\n",
    "# Assuming the 'presence' column might have different casing or unexpected ordering, we map values to a helper numeric column\n",
    "statsDataFrame['presence_order'] = statsDataFrame['presence'].map({'Present': 1, 'Absent': 2})  # Smaller numbers sort first\n",
    "# Sorting by 'season' and 'presence_order'\n",
    "statsDataFrame.sort_values(by=['season', 'presence_order'], ascending=[True, True], inplace=True)\n",
    "# Reset the index after sorting\n",
    "statsDataFrame.reset_index(drop=True, inplace=True)\n",
    "# Drop the 'presence_order' column as it's no longer needed after sorting\n",
    "statsDataFrame.drop('presence_order', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85a8499",
   "metadata": {},
   "source": [
    "## Fill up rows with \"absent\" status with NaN values for their stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42c8ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which columns to fill with NaN\n",
    "stats_columns = [col for col in statsDataFrame.columns if col not in ['team', 'season', 'presence']]\n",
    "\n",
    "# Set columns to NaN for rows where 'presence' is 'Absent'\n",
    "statsDataFrame.loc[statsDataFrame['presence'] == 'Absent', stats_columns] = np.nan\n",
    "\n",
    "statsDataFrame.head(40)\n",
    "statsDataFrame.to_csv('abc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00efe85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
